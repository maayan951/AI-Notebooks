{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding AUC ‚Äî ROC and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the ROC curve?\n",
    "2. What is the area under the curve?\n",
    "3. What is the decision threshold in binary classification?\n",
    "4. What AUC value is acceptable for a classification model?\n",
    "5. What is the Precision-Recall curve?\n",
    "6. When should you use precision-recall and ROC curves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- üìé What is ROC (Receiver operating characteristic) curve?\n",
    "\n",
    "If you google the ROC curve, you will get the following answer from Wikipedia:\n",
    "\n",
    "‚ÄúA receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.‚Äù (<a href src=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\">ref</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into the ROC curve, we need to remember what a confusion matrix is.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/640/1*6CeHh8_2SEkXFyJPzzfMKw.png\">\n",
    "\n",
    "The confusion matrix helps us visualize whether the model is ‚Äúmistaken‚Äù in distinguishing between two classes. It is a 2x2 matrix. The row names are the actuals from the test set, and the column names are the ones predicted by the model.\n",
    "\n",
    "The confusion matrix helps us visualize whether the model is ‚Äúmistaken‚Äù in distinguishing between two classes. It is a 2x2 matrix. The row names are the actuals from the test set, and the column names are the ones predicted by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix helps us visualize whether the model is ‚Äúmistaken‚Äù in distinguishing between two classes. It is a 2x2 matrix. The row names are the actuals from the test set, and the column names are the ones predicted by the model.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/434/1*H6OwMbBSNdI1kPTLfCTdFg.png\">\n",
    "\n",
    "In turn, FPR is the ratio of false positive predictions to the total number of actual negative samples. It is the same as 1 ‚Äî Specificity:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/408/1*l8uyjg5TDY62CR6UW0OeSA.png\">\n",
    "\n",
    "The ROC Curve is plotted based on TPR and FPR.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/720/1*7F_5WvU7UGtmI2sIOkxMqA.jpeg\">\n",
    "\n",
    "By using TPR and FPR, the ROC Curve shows your classification model‚Äôs performance at all classification thresholds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href src=\"https://medium.com/@data.science.enthusiast/auc-roc-curve-ae9180eaf4f7\">Source</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "939696d70912113cfba5abfc38042432dae0b1972083a020fa8012dfb8da49d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
